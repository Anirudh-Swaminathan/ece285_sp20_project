{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torchvision as tv\n",
    "import torch.utils.data as td\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import models.nntools_modified as nt\n",
    "import models.framework as fw\n",
    "import models.framework_varying as fwv\n",
    "import models.framework_single_varying as fwsv\n",
    "import utils.config as cfg\n",
    "from utils.datareader_toy import toyScenesdata\n",
    "\n",
    "from utils.visualization import *\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "# import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 1000 \n",
      "700\n",
      "200\n",
      "100\n",
      "Read in 1000 \n",
      "700\n",
      "200\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "net = fwv.MultiAgentNetwork(cfg.FCN_OUT, cfg.NUM_INTENTS, cfg.SCENE_OUT,\n",
    "                                cfg.INTENT_IN, cfg.INTENT_OUT, cfg.SCORE_IN)\n",
    "\n",
    "dataset = toyScenesdata(set_name=\"test\", traj_time=cfg.PAST_TRAJECTORY_TIME)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "net = net.to(device)\n",
    "test_set = toyScenesdata(set_name=\"test\")\n",
    "# output_dir = \"data/res_gpu_original_downsample_epoch_75_pt_5/\" # output_dir = cfg.EXP_NAME\n",
    "output_dir = cfg.OUTPUT_PATH + cfg.EXP_NAME\n",
    "\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(checkpoint):\n",
    "    \"\"\"Loads the experiment from the input checkpoint.\"\"\"\n",
    "    net.load_state_dict(checkpoint['Net'])\n",
    "    optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "    history = checkpoint['History']\n",
    "\n",
    "    # The following loops are used to fix a bug that was\n",
    "    # discussed here: https://github.com/pytorch/pytorch/issues/2830\n",
    "    # (it is supposed to be fixed in recent PyTorch version)\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.to(net.device)\n",
    "\n",
    "def load():\n",
    "    \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path,\n",
    "                            map_location=net.device)\n",
    "    load_state_dict(checkpoint)\n",
    "#     del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = td.DataLoader(test_set, batch_size=cfg.BATCH_SIZE, shuffle=cfg.SHUFFLE, drop_last=cfg.DROP_LAST, pin_memory=True)\n",
    "\n",
    "# Initialize history\n",
    "history = []\n",
    "\n",
    "# Define checkpoint paths\n",
    "# if output_dir is None:\n",
    "#     output_dir = 'experiment_{}'.format(time.time())\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(output_dir, \"checkpoint.pth.tar\")\n",
    "config_path = os.path.join(output_dir, \"config.txt\")\n",
    "\n",
    "# Transfer all local arguments/variables into attributes\n",
    "# locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "# self.__dict__.update(locs)\n",
    "\n",
    "# Load checkpoint and check compatibility\n",
    "if os.path.isfile(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        if f.read()[:-1] != repr(self):\n",
    "            raise ValueError(\n",
    "                \"Cannot create this experiment: \"\n",
    "                \"I found a checkpoint conflicting with the current setting.\")\n",
    "    load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - replace these with the inputs used for the network\n",
    "# ls - the entire groundtruth trajectory of the agent\n",
    "# vs - the entire groundtruth velocities of the agent\n",
    "\n",
    "# ls, vs -> required for plotting the actual trajectories\n",
    "# vs additionally required for the initial velocity value\n",
    "# s_points -> refers to the actual data that is used in init.npy file.\n",
    "# these are the starting conditions set initially for the image\n",
    "data_path = cfg.DATA_PATH + \"2/2716/\"\n",
    "base_path = cfg.ACTUAL_PATH + \"/2/2716/\"\n",
    "s_points = np.load(base_path + \"init.npy\", allow_pickle=True)\n",
    "vs = np.load(base_path + \"vs.npy\")\n",
    "ls = np.load(base_path + \"ls.npy\")\n",
    "# im = imageio.imread(\"../data/toydataset/2/2716/scene.png\")\n",
    "im = np.array(cv2.imread(base_path + \"scene.png\"))\n",
    "print(im.shape)\n",
    "\n",
    "print(\"Displaying input to the network\")\n",
    "fig = plt.figure()\n",
    "plt.imshow(im)\n",
    "# plt.savefig(\"test_input.png\")\n",
    "plt.show()\n",
    "\n",
    "# TODO - compute the new intents from the network\n",
    "new_intents = np.array([2, 3])\n",
    "f, f_new, c = visualize(new_intents, s_points, ls, vs)\n",
    "# f.savefig(\"test_old.png\")\n",
    "# f_new.savefig(\"test_new.png\")\n",
    "print(\"Displaying Groundtruth complete trajectory\")\n",
    "f.show()\n",
    "print(\"Displaying Predicted complete trajectory\")\n",
    "f_new.show()\n",
    "if c:\n",
    "    print(\"Collision occurred for new intents\")\n",
    "else:\n",
    "    print(\"Successful new trajectory was generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3) (2, 24) (2,)\n"
     ]
    }
   ],
   "source": [
    "# sample_img = imageio.imread(\"../data/toydataset_resampled/2/2716/scene.png\")\n",
    "sample_img = np.array(cv2.imread(data_path + \"scene.png\"))\n",
    "sample_ls = np.load(data_path + \"ls.npy\")\n",
    "sample_gt = np.array(list(np.array(np.load(data_path + \"init.npy\", allow_pickle=True))))\n",
    "print(sample_img.shape, sample_ls.shape, sample_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 100, 3])\n",
      "torch.Size([1, 2, 24])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "sample_img = torch.from_numpy(sample_img)\n",
    "sample_img = sample_img.view(1, *sample_img.size())\n",
    "print(sample_img.shape)\n",
    "sample_ls = torch.from_numpy(sample_ls)\n",
    "sample_ls = sample_ls.view(1, *sample_ls.size())\n",
    "print(sample_ls.shape)\n",
    "sample_gt = torch.from_numpy(sample_gt)\n",
    "sample_gt = sample_gt.view(1, *sample_gt.size())\n",
    "print(sample_gt.shape)\n",
    "sample_img = sample_img.to(net.device)\n",
    "sample_ls = sample_ls.to(net.device)\n",
    "sample_gt = sample_gt.to(net.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Scene Output shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n",
      "traj_output.shape:  torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "y, d = net(sample_img, sample_ls, sample_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1257, -0.1256, -0.1258, -0.1255, -0.1257, -0.1255, -0.1257, -0.1255,\n",
      "         -0.1259, -0.1258, -0.1261, -0.1257, -0.1255, -0.1253, -0.1256, -0.1253]],\n",
      "       device='cuda:0', grad_fn=<CopyBackwards>)\n",
      "tensor(5, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(output[0], 1)\n",
    "print(predicted)\n",
    "# print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "#                               for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "dimension specified as 0 but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f38f8547b0b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ece285/ece285_sp20_project/models/framework.py\u001b[0m in \u001b[0;36mcriterion\u001b[0;34m(self, y, d)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or more dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n",
      "\u001b[0;31mIndexError\u001b[0m: dimension specified as 0 but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "loss = net.criterion(y, d)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.Softmax(dim=1)\n",
    "sout = s(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_intents = list()\n",
    "n_modes = output.shape[1]\n",
    "n_agents = 0\n",
    "nm = n_modes\n",
    "while nm != 1:\n",
    "    n_agents += 1\n",
    "    nm = nm // 4\n",
    "overall_ind = torch.argmax(sout, dim=1)\n",
    "n_samples = overall_ind.shape[0]\n",
    "for i in range(n_samples):\n",
    "    ints = list()\n",
    "    oin = oind[i]\n",
    "    for k in range(1, n_agents+1):\n",
    "        ints.append((oin%4**k).item())\n",
    "        oin = oin//4**k\n",
    "    predicted_intents.append(np.array(ints))\n",
    "print(predicted_intents)\n",
    "print(len(predicted_intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_intents in predicted_intents:\n",
    "    print(new_intents)\n",
    "    f, f_new, c = visualize(new_intents, s_points, ls, vs)\n",
    "    # f.savefig(\"test_old.png\")\n",
    "    # f_new.savefig(\"test_new.png\")\n",
    "    print(\"Displaying Groundtruth complete trajectory\")\n",
    "    f.show()\n",
    "    print(\"Displaying Predicted complete trajectory\")\n",
    "    f_new.show()\n",
    "    if c:\n",
    "        print(\"Collision occurred for new intents\")\n",
    "    else:\n",
    "        print(\"Successful new trajectory was generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
