{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torchvision as tv\n",
    "import torch.utils.data as td\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import models.nntools_modified as nt\n",
    "import models.framework as fw\n",
    "import utils.config as cfg\n",
    "from utils.datareader_toy import toyScenesdata\n",
    "\n",
    "from utils.visualization import *\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "# import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 5000 \n",
      "700\n",
      "200\n",
      "100\n",
      "Read in 5000 \n",
      "700\n",
      "200\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "net = fw.MultiAgentNetwork(cfg.FCN_OUT, cfg.NUM_INTENTS, cfg.SCENE_OUT,\n",
    "                                cfg.INTENT_IN, cfg.INTENT_OUT, cfg.SCORE_IN)\n",
    "\n",
    "dataset = toyScenesdata(set_name=\"test\", traj_time=cfg.PAST_TRAJECTORY_TIME)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "net = net.to(device)\n",
    "test_set = toyScenesdata(set_name=\"test\")\n",
    "output_dir = \"data/res_gpu_original_downsample_epoch_75_pt_5/\" # output_dir = cfg.EXP_NAME\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_dict(checkpoint):\n",
    "    \"\"\"Loads the experiment from the input checkpoint.\"\"\"\n",
    "    net.load_state_dict(checkpoint['Net'])\n",
    "    optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "    history = checkpoint['History']\n",
    "\n",
    "    # The following loops are used to fix a bug that was\n",
    "    # discussed here: https://github.com/pytorch/pytorch/issues/2830\n",
    "    # (it is supposed to be fixed in recent PyTorch version)\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.to(net.device)\n",
    "\n",
    "def load():\n",
    "    \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path,\n",
    "                            map_location=net.device)\n",
    "    load_state_dict(checkpoint)\n",
    "#     del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = td.DataLoader(test_set, batch_size=cfg.BATCH_SIZE, shuffle=cfg.SHUFFLE, drop_last=cfg.DROP_LAST, pin_memory=True)\n",
    "\n",
    "# Initialize history\n",
    "history = []\n",
    "\n",
    "# Define checkpoint paths\n",
    "# if output_dir is None:\n",
    "#     output_dir = 'experiment_{}'.format(time.time())\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(output_dir, \"checkpoint.pth.tar\")\n",
    "config_path = os.path.join(output_dir, \"config.txt\")\n",
    "\n",
    "# Transfer all local arguments/variables into attributes\n",
    "# locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "# self.__dict__.update(locs)\n",
    "\n",
    "# Load checkpoint and check compatibility\n",
    "if os.path.isfile(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        if f.read()[:-1] != repr(self):\n",
    "            raise ValueError(\n",
    "                \"Cannot create this experiment: \"\n",
    "                \"I found a checkpoint conflicting with the current setting.\")\n",
    "    load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiAgentNetwork(\n",
       "  (cross_entropy): CrossEntropyLoss()\n",
       "  (scene): ResnetSceneContext(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=32, bias=True)\n",
       "  )\n",
       "  (past): FCNPastProcess(\n",
       "    (fc1): Linear(in_features=10, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (intent): IntentionEmbedding(\n",
       "    (emb): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "    )\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (score): ScoringFunction(\n",
       "    (score): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "Displaying input to the network\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying Groundtruth complete trajectory\n",
      "Displaying Predicted complete trajectory\n",
      "Collision occurred for new intents\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO - replace these with the inputs used for the network\n",
    "# ls - the entire groundtruth trajectory of the agent\n",
    "# vs - the entire groundtruth velocities of the agent\n",
    "\n",
    "# ls, vs -> required for plotting the actual trajectories\n",
    "# vs additionally required for the initial velocity value\n",
    "# s_points -> refers to the actual data that is used in init.npy file.\n",
    "# these are the starting conditions set initially for the image\n",
    "s_points = np.load(\"../data/toydataset/2/2716/init.npy\", allow_pickle=True)\n",
    "vs = np.load(\"../data/toydataset/2/2716/vs.npy\")\n",
    "ls = np.load(\"../data/toydataset/2/2716/ls.npy\")\n",
    "# im = imageio.imread(\"../data/toydataset/2/2716/scene.png\")\n",
    "im = np.array(cv2.imread(\"../data/toydataset/2/2716/scene.png\"))\n",
    "print(im.shape)\n",
    "\n",
    "print(\"Displaying input to the network\")\n",
    "fig = plt.figure()\n",
    "plt.imshow(im)\n",
    "# plt.savefig(\"test_input.png\")\n",
    "plt.show()\n",
    "\n",
    "# TODO - compute the new intents from the network\n",
    "new_intents = np.array([2, 3])\n",
    "f, f_new, c = visualize(new_intents, s_points, ls, vs)\n",
    "# f.savefig(\"test_old.png\")\n",
    "# f_new.savefig(\"test_new.png\")\n",
    "print(\"Displaying Groundtruth complete trajectory\")\n",
    "f.show()\n",
    "print(\"Displaying Predicted complete trajectory\")\n",
    "f_new.show()\n",
    "if c:\n",
    "    print(\"Collision occurred for new intents\")\n",
    "else:\n",
    "    print(\"Successful new trajectory was generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3) (2, 24) (2,)\n"
     ]
    }
   ],
   "source": [
    "# sample_img = imageio.imread(\"../data/toydataset_resampled/2/2716/scene.png\")\n",
    "sample_img = np.array(cv2.imread(\"../data/toydataset_resampled/2/2716/scene.png\"))\n",
    "sample_ls = np.load(\"../data/toydataset_resampled/2/2716/ls.npy\")\n",
    "sample_gt = np.array(list(np.array(np.load(\"../data/toydataset_resampled/2/2716/init.npy\", allow_pickle=True))))\n",
    "print(sample_img.shape, sample_ls.shape, sample_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 100, 3])\n",
      "torch.Size([1, 2, 24])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "sample_img = torch.from_numpy(sample_img)\n",
    "sample_img = sample_img.view(1, *sample_img.size())\n",
    "print(sample_img.shape)\n",
    "sample_ls = torch.from_numpy(sample_ls)\n",
    "sample_ls = sample_ls.view(1, *sample_ls.size())\n",
    "print(sample_ls.shape)\n",
    "sample_gt = torch.from_numpy(sample_gt)\n",
    "sample_gt = sample_gt.view(1, *sample_gt.size())\n",
    "print(sample_gt.shape)\n",
    "sample_img = sample_img.to(net.device)\n",
    "sample_ls = sample_ls.to(net.device)\n",
    "sample_gt = sample_gt.to(net.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../models/framework.py:181: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Tensors must have same number of dimensions: got 1 and 2 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:62",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-887821c2a972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ece_285_sp20_project/ece285_sp20_project/models/framework.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, past_traj, gt_future)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtraj_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;31m# traj_output: (n_batch, intent_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mcombined_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0;31m# combined_output: (nbatch, scene_out+intent_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Tensors must have same number of dimensions: got 1 and 2 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:62"
     ]
    }
   ],
   "source": [
    "output = net(sample_img, sample_ls, sample_gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
