{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# python2 and python3 compatibility between loaded modules\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from PIL import Image\n",
    "from json import encoder\n",
    "import pylab\n",
    "import skimage.io as io\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torchvision as tv\n",
    "import torch.utils.data as td\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import models.nntools_modified_varying as nt\n",
    "import utils.config as cfg\n",
    "from utils.datareader_toy import toyScenesdata\n",
    "\n",
    "# All imports here\n",
    "# Reading files\n",
    "\n",
    "# Vector manipulations\n",
    "\n",
    "# DL framework\n",
    "# torch\n",
    "\n",
    "# import toy dataset class\n",
    "\n",
    "# Plotting images\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "# PIL Image\n",
    "\n",
    "# regex for captions\n",
    "\n",
    "# import nntools\n",
    "\n",
    "# import add for fast addition between lists\n",
    "\n",
    "# json for dumping stuff onto files as output\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "\n",
    "# set the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "\n",
    "# NN Classifier from nntools\n",
    "\n",
    "class NNClassifier(nt.NeuralNetwork):\n",
    "    def __init__(self):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def criterion(self, y, d):\n",
    "        return self.cross_entropy(y, d)\n",
    "\n",
    "\n",
    "class CNNSceneContext(nn.Module):\n",
    "    def __init__(self, scene_out, fine_tuning=True):\n",
    "        super(CNNSceneContext, self).__init__()\n",
    "        vgg = tv.models.vgg16_bn(pretrained=True)\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = fine_tuning\n",
    "        self.features = vgg.features\n",
    "        # the average pooling is the same\n",
    "        self.avgpool = vgg.avgpool\n",
    "        # the classifier is also the same\n",
    "        self.classifier = vgg.classifier\n",
    "        # CODE to change the final classifier layer\n",
    "        num_ftrs = vgg.classifier[6].in_features\n",
    "        self.classifier[6] = nn.Linear(num_ftrs, scene_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # COMPLETE the forward prop\n",
    "        # x: torch.Size([16, 480, 640, 3])\n",
    "        x = x.permute(0,3,1,2)\n",
    "        x = x.float()\n",
    "        f = self.features(x)\n",
    "        f = self.avgpool(f)\n",
    "        f = torch.flatten(f, 1)\n",
    "        f = self.classifier(f)\n",
    "        return f\n",
    "\n",
    "\n",
    "class ResnetSceneContext(nn.Module):\n",
    "    def __init__(self, scene_out, fine_tuning=True):\n",
    "        super(ResnetSceneContext, self).__init__()\n",
    "        resnet = tv.models.resnet18(pretrained=True)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = fine_tuning\n",
    "        \n",
    "        # network definitions\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        \n",
    "        # layers\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "\n",
    "        # avgpool\n",
    "        self.avgpool = resnet.avgpool\n",
    "        # fc\n",
    "        self.fc = resnet.fc\n",
    "\n",
    "        # change output layer\n",
    "        num_ftrs = resnet.fc.in_features\n",
    "        self.fc = nn.Linear(num_ftrs, scene_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward prop through the network\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.float()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        f = self.layer1(x)\n",
    "        f = self.layer2(f)\n",
    "        f = self.layer3(f)\n",
    "        f = self.layer4(f)\n",
    "        a = self.avgpool(f)\n",
    "        a = torch.flatten(a, 1)\n",
    "        y = self.fc(a)\n",
    "        return y\n",
    "\n",
    "# class RNNAnchorProcess(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         pass\n",
    "\n",
    "\n",
    "# class RNNPastProcess(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def forward(self):\n",
    "#         pass\n",
    "\n",
    "\n",
    "#     def greedy_sample(self):\n",
    "#         \"\"\" Method to greedily sample from the RNN \"\"\"\n",
    "#         pass\n",
    "\n",
    "class FCNPastProcess(nn.Module):\n",
    "    def __init__(self, fcn_out):\n",
    "        '''\n",
    "        fcn_out: Num channels in the output (number of intents)\n",
    "        '''\n",
    "        super(FCNPastProcess, self).__init__()\n",
    "        self.fc1 = nn.Linear(int(cfg.PAST_TRAJECTORY_LENGTH * 2), 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, fcn_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x dim: batch_size * (PAST_TRAJECTORY_LENGTH * 2)\n",
    "        '''\n",
    "        # assert (x.size() == torch.Size([2,PAST_TRAJECTORY_LENGTH])), print(\"Incorrect tensor shape passed to FCN\")\n",
    "#         print(\"In model: \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "class IntentionEmbedding(nn.Module):\n",
    "    def __init__(self, intent_in, intent_out):\n",
    "        # intent_in: dim of past trajectory features\n",
    "        super(IntentionEmbedding, self).__init__()\n",
    "        self.emb = nn.Sequential(\n",
    "            nn.Linear(4, 32)\n",
    "        )\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(32+intent_in, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, intent_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, intention):\n",
    "        # x: batch x n_vehicles x intent_in, past trajectory features\n",
    "        # intention: batch x n_vehicles x 4, one-hot embedding of intentions\n",
    "        intention = self.emb(intention)\n",
    "        y = torch.cat((x, intention), dim=2)\n",
    "        y = self.encode(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ScoringFunction(nn.Module):\n",
    "    def __init__(self, fdim):\n",
    "        super(ScoringFunction, self).__init__()\n",
    "        self.score = nn.Sequential(\n",
    "            nn.Linear(fdim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        # self.sm=nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: batch x fdim (scene+past_intent_embedding)\n",
    "        y = self.score(x).squeeze()\n",
    "        # y=self.sm(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class MultiAgentNetwork(NNClassifier):\n",
    "    def __init__(self, fcn_out, n_intents, scene_out, intent_in, intent_out, score_in, fine_tuning=True):\n",
    "        \"\"\"\n",
    "        n_intents - number of intents in dataset\n",
    "        scene_out - dimension of the output for the scene parsing CNN\n",
    "        intent_in - dimension of the input for the intention embedding\n",
    "        intent_out - dimension of the output for the intention embedding\n",
    "        score_in - dimension of the input of the scoring module\n",
    "        \"\"\"\n",
    "        super(MultiAgentNetwork, self).__init__()\n",
    "        if cfg.BACKBONE == \"VGG\":\n",
    "            self.scene = CNNSceneContext(scene_out, fine_tuning)\n",
    "        elif cfg.BACKBONE == \"RESNET\":\n",
    "            self.scene = ResnetSceneContext(scene_out, fine_tuning)\n",
    "        else:\n",
    "            print(\"Incorrect BACKBONE specified in config.py\")\n",
    "            return(-1)\n",
    "        self.past = FCNPastProcess(fcn_out); self.past.double()\n",
    "        self.intent = IntentionEmbedding(intent_in, intent_out)\n",
    "        self.score = ScoringFunction(scene_out+intent_out)\n",
    "        self.n_intents = n_intents\n",
    "\n",
    "    def forward(self, img, past_traj, gt_future):\n",
    "        '''\n",
    "        img: torch.Size([16, 480, 640, 3])\n",
    "        past_traj: torch.Size([16, 2, 24])\n",
    "        gt_future: torch.Size([16, 2])\n",
    "        '''\n",
    "        # past_traj: (n_batch, n_vehicles, ...)\n",
    "        # gt_future: (n_batch, n_vehicles)\n",
    "        # print(\"img shape: \", img.shape)\n",
    "        # print(\"past traj shape: \", past_traj.shape)\n",
    "        # print(\"gt_future shape: \", gt_future.shape)\n",
    "\n",
    "        scene_output = self.scene(img) #TODO: Fix dimension mismatch\n",
    "        # print(\"==================================\")\n",
    "        # print(\"Scene Output shape: \", scene_output.shape)\n",
    "\n",
    "        n_batch = past_traj.shape[0]\n",
    "\n",
    "        n_vehicles = past_traj.shape[1]\n",
    "        n_modes = self.n_intents**n_vehicles\n",
    "        scores = torch.zeros(n_batch, n_modes)\n",
    "\n",
    "        fcn_out = torch.rand([n_batch, n_vehicles, cfg.FCN_OUT])\n",
    "        for agent in range(n_vehicles):\n",
    "            fcn_out[:,agent,:] = self.past(past_traj[:,agent,:int(cfg.PAST_TRAJECTORY_LENGTH*2)]) #torch.Size([16, 32])\n",
    "        fcn_out = fcn_out.to(self.device)\n",
    "        # print(\"==================================\")\n",
    "        gt_future = gt_future.long()\n",
    "        gt_index = self.n_intents**torch.arange(n_vehicles)\n",
    "        gt_index = gt_index.repeat(n_batch, 1)\n",
    "        gt_index = gt_index.to(self.device)\n",
    "\n",
    "        gt_index = torch.sum(gt_index*gt_future, dim=1, keepdim=True)\n",
    "        \n",
    "        for mode in range(n_modes):\n",
    "            intentions = torch.zeros(n_batch, n_vehicles, self.n_intents) \n",
    "            for agent in range(n_vehicles):\n",
    "                intention_index = int(mode/self.n_intents**(agent)) % self.n_intents\n",
    "                intentions[..., agent, intention_index] = 1\n",
    "            # past_output: (n_batch, n_vehicles, intent_in)\n",
    "\n",
    "            # print(\"==================================\")\n",
    "\n",
    "            intentions = intentions.to(self.device)\n",
    "            traj_output = self.intent(fcn_out, intentions) \n",
    "            # print(traj_output.shape)\n",
    "\n",
    "            # traj_output: (n_batch, n_vehicles, intent_out)\n",
    "            # or mean, or max\n",
    "            traj_output = torch.sum(traj_output, dim=1).squeeze()\n",
    "            # traj_output: (n_batch, intent_out)\n",
    "            combined_output = torch.cat((scene_output, traj_output), dim=1)\n",
    "            # combined_output: (nbatch, scene_out+intent_out)\n",
    "            scores[:, mode] = self.score(combined_output)\n",
    "        #scores = F.softmax(scores)\n",
    "        scores = scores.to(self.device)\n",
    "        return scores, gt_index.squeeze()\n",
    "\n",
    "\n",
    "class ToyStatsManager(nt.StatsManager):\n",
    "    def __init__(self):\n",
    "        super(ToyStatsManager, self).__init__()\n",
    "\n",
    "    def init(self):\n",
    "        super(ToyStatsManager, self).init()\n",
    "        self.running_accuracy = 0\n",
    "\n",
    "    def accumulate(self, loss, x, y, d):\n",
    "        # TODO - modify the input params to accept the past trajectories also\n",
    "        super(ToyStatsManager, self).accumulate(loss, x, y, d)\n",
    "\n",
    "        # get the indices of the maximum activation of softmax for each sample\n",
    "        _, l = torch.max(y, 1)\n",
    "\n",
    "        # count the running average fraction of correctly classified samples\n",
    "        self.running_accuracy += torch.mean((l == d).float())\n",
    "\n",
    "    def summarize(self):\n",
    "        # this is the average loss when called\n",
    "        loss = super(ToyStatsManager, self).summarize()\n",
    "\n",
    "        # this is the average accuracy percentage when called\n",
    "        accuracy = 100 * self.running_accuracy / self.number_update\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "\n",
    "\n",
    "# class to house training stuff\n",
    "class TrainNetwork(object):\n",
    "    def __init__(self):\n",
    "        self._init_paths()\n",
    "\n",
    "        self.training_dataset = [toyScenesdata(traj_time=cfg.PAST_TRAJECTORY_TIME), toyScenesdata(\"train\",agents = 3, traj_time=cfg.PAST_TRAJECTORY_TIME), toyScenesdata(\"train\",agents = 4, traj_time=cfg.PAST_TRAJECTORY_TIME)]\n",
    "        self.val_dataset = [toyScenesdata(set_name=\"val\", traj_time=cfg.PAST_TRAJECTORY_TIME), toyScenesdata(set_name=\"val\",agents = 3, traj_time=cfg.PAST_TRAJECTORY_TIME), toyScenesdata(set_name=\"val\",agents = 4, traj_time=cfg.PAST_TRAJECTORY_TIME)]\n",
    "        self.test_dataset = [toyScenesdata(set_name=\"test\", traj_time=cfg.PAST_TRAJECTORY_TIME), toyScenesdata(set_name=\"test\",agents = 3, traj_time=cfg.PAST_TRAJECTORY_TIME), toyScenesdata(set_name=\"test\",agents = 4, traj_time=cfg.PAST_TRAJECTORY_TIME)]\n",
    "        self._init_train_stuff()\n",
    "\n",
    "    def _init_paths(self):\n",
    "        # data loading\n",
    "        self.exp_name = cfg.EXP_NAME\n",
    "        self.dataset_root_dir = cfg.DATA_PATH\n",
    "\n",
    "        # output directory for training checkpoints\n",
    "        # This changes for every experiment\n",
    "        self.op_dir = cfg.OUTPUT_PATH + self.exp_name # + <experiment nunmber>\n",
    "\n",
    "    def _init_train_stuff(self):\n",
    "        self.lr = 5e-4\n",
    "        # Change these values #DONE\n",
    "        self.fcn_out = cfg.FCN_OUT\n",
    "        self.n_intents = cfg.NUM_INTENTS\n",
    "        self.scene_out = cfg.SCENE_OUT\n",
    "        self.intent_in = cfg.INTENT_IN\n",
    "        self.intent_out = cfg.INTENT_OUT\n",
    "        self.score_in = cfg.SCORE_IN\n",
    "\n",
    "        net = MultiAgentNetwork(self.fcn_out, self.n_intents, self.scene_out,\n",
    "                                self.intent_in, self.intent_out, self.score_in)\n",
    "        self.net = net.to(device)\n",
    "        self.adam = torch.optim.Adam(net.parameters(), lr=self.lr)\n",
    "        self.stats_manager = ToyStatsManager()\n",
    "        self.exp = nt.Experiment(self.net, self.training_dataset, self.val_dataset, self.test_dataset, self.adam,\n",
    "                                 self.stats_manager, output_dir=self.op_dir, perform_validation_during_training=True)\n",
    "\n",
    "    def myimshow(self, img, ax=plt):\n",
    "        image = image.to('cpu').numpy()\n",
    "        image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "        image = (image + 1) / 2\n",
    "        image[image < 0] = 0\n",
    "        image[image > 1] = 1\n",
    "        h = ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        return h\n",
    "\n",
    "    def plot(self, exp, fig, axes):\n",
    "        axes[0].clear()\n",
    "        axes[1].clear()\n",
    "        # Plot the training loss over the epochs\n",
    "        axes[0].plot([exp.history[k][0]['loss']\n",
    "                      for k in range(exp.epoch)], label=\"training loss\")\n",
    "        # Plot the evaluation loss over the epochs\n",
    "        axes[0].plot([exp.history[k][1]['loss'] for k in range(\n",
    "            exp.epoch)], color='orange', label=\"evaluation loss\")\n",
    "        # legend for the plot\n",
    "        axes[0].legend()\n",
    "        # xlabel and ylabel\n",
    "        axes[0].set_xlabel(\"Epoch\")\n",
    "        axes[0].set_ylabel(\"Loss\")\n",
    "        # Plot the training accuracy over the epochs\n",
    "        axes[1].plot([exp.history[k][0]['accuracy']\n",
    "                      for k in range(exp.epoch)], label=\"training accuracy\")\n",
    "        # Plot the evaluation accuracy over the epochs\n",
    "        axes[1].plot([exp.history[k][1]['accuracy']\n",
    "                      for k in range(exp.epoch)], label=\"evaluation accuracy\")\n",
    "        # legend for the plot\n",
    "        axes[1].legend()\n",
    "        # xlabel and ylabel\n",
    "        axes[1].set_xlabel(\"Epoch\")\n",
    "        axes[1].set_ylabel(\"Accuracy\")\n",
    "        plt.tight_layout()\n",
    "        # set the title for the figure\n",
    "        # fig.suptitle(\"Loss and Accuracy metrics\")\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    def run_plot_exp(self):\n",
    "        fig, axes = plt.subplots(ncols=2, figsize=(7, 3))\n",
    "        self.exp.run(num_epochs=cfg.NUM_EPOCHS, plot=lambda exp: self.plot(\n",
    "            exp, fig=fig, axes=axes))\n",
    "\n",
    "    def run_exp(self):\n",
    "        # RUN on the server, without plotting\n",
    "        self.exp.run(num_epochs=cfg.NUM_EPOCHS)\n",
    "\n",
    "    def save_evaluation(self):\n",
    "        exp_val = self.exp.evaluate()\n",
    "        with open(self.op_dir+'val_result.txt', 'a') as t_file:\n",
    "            print(exp_val)\n",
    "            t_file.write(str(exp_val))\n",
    "\n",
    "    def save_testing(self):\n",
    "        exp_test = self.exp.test()\n",
    "        with open(self.op_dir+'test_result.txt', 'a') as t_file:\n",
    "            print(exp_test)\n",
    "            t_file.write(str(exp_test))\n",
    "\n",
    "def main():\n",
    "    tn = TrainNetwork()\n",
    "    tn.run_plot_exp()\n",
    "    tn.save_evaluation()\n",
    "    tn.save_testing()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
